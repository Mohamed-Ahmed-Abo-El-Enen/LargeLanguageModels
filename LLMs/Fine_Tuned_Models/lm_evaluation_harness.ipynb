{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y3-InTYYEe3R"},"outputs":[],"source":["# !pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git@big-refactor"]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2ZBlliXNKZ3","outputId":"850aa811-4547-4408-f763-5b2236fc9260","executionInfo":{"status":"ok","timestamp":1711623716456,"user_tz":-120,"elapsed":10841,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n","    Setting a new token will erase the existing one.\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /content/transformers_cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["YAML_mmlu_clinical_knowledge_string = '''\n","group: mmlu\n","task: mmlu_clinical_knowledge\n","dataset_path: cais/mmlu\n","dataset_name: clinical_knowledge\n","description: \"The following are multiple choice questions (with answers) about clinical knowledge.\\n\\n\"\n","test_split: test\n","fewshot_split: dev\n","fewshot_config:\n","  sampler: first_n\n","output_type: multiple_choice\n","doc_to_text: \"{{question.strip()}}\\nA. {{choices[0]}}\\nB. {{choices[1]}}\\nC. {{choices[2]}}\\nD. {{choices[3]}}\\nAnswer:\"\n","doc_to_choice: [\"A\", \"B\", \"C\", \"D\"]\n","doc_to_target: answer\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","  - metric: acc_norm\n","    aggregation: mean\n","    higher_is_better: true\n","'''\n","with open('mmlu_clinical_knowledge.yaml', 'w') as f:\n","    f.write(YAML_mmlu_clinical_knowledge_string)"],"metadata":{"id":"tgFlpDLVFRRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!accelerate launch -m lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.2,load_in_4bit=True,dtype=\"bfloat16\" \\\n","    --include_path ./ \\\n","    --tasks mmlu_clinical_knowledge \\\n","    --batch_size 32 \\\n","    --output_path results_mmlu_clinical_knowledge.jsonl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYeTtTnkkv0C","executionInfo":{"status":"ok","timestamp":1711633557943,"user_tz":-120,"elapsed":99840,"user":{"displayName":"","userId":""}},"outputId":"dd4c73f8-e06a-458b-ed86-de95ddf6ecb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `2`\n","\t\tMore than one GPU was found, enabling multi-GPU training.\n","\t\tIf this was unintended please pass in `--num_processes=1`.\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n","2024-03-28:13:44:24,702 INFO     [utils.py:148] Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","2024-03-28:13:44:24,708 INFO     [utils.py:148] Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","2024-03-28:13:44:24,993 INFO     [config.py:58] PyTorch version 2.2.1 available.\n","2024-03-28:13:44:24,993 INFO     [config.py:95] TensorFlow version 2.15.0 available.\n","2024-03-28:13:44:24,994 INFO     [config.py:58] PyTorch version 2.2.1 available.\n","2024-03-28:13:44:24,995 INFO     [config.py:108] JAX version 0.4.23 available.\n","2024-03-28:13:44:24,995 INFO     [config.py:95] TensorFlow version 2.15.0 available.\n","2024-03-28:13:44:24,996 INFO     [config.py:108] JAX version 0.4.23 available.\n","2024-03-28 13:44:25.535183: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-28 13:44:25.535183: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-28 13:44:25.535278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-28 13:44:25.535278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-28 13:44:25.538495: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-28 13:44:25.538495: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-28 13:44:26.967569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-28 13:44:26.967752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-28:13:44:30,643 INFO     [__main__.py:132] Verbosity set to INFO\n","2024-03-28:13:44:30,643 INFO     [__main__.py:132] Verbosity set to INFO\n","2024-03-28:13:44:40,880 INFO     [__main__.py:143] Including path: ./\n","2024-03-28:13:44:41,185 INFO     [__main__.py:143] Including path: ./\n","2024-03-28:13:44:42,257 INFO     [__main__.py:205] Selected Tasks: ['mmlu_clinical_knowledge']\n","2024-03-28:13:44:42,258 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.\n","2024-03-28:13:44:42,608 INFO     [__main__.py:205] Selected Tasks: ['mmlu_clinical_knowledge']\n","2024-03-28:13:44:42,609 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","Downloading shards: 100% 19/19 [00:00<00:00, 15941.54it/s]\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","Downloading shards: 100% 19/19 [00:00<00:00, 16703.37it/s]\n","Loading checkpoint shards: 100% 19/19 [00:33<00:00,  1.76s/it]\n","Loading checkpoint shards: 100% 19/19 [00:33<00:00,  1.78s/it]\n","2024-03-28:13:45:27,234 INFO     [huggingface.py:320] Using 2 devices with data parallelism\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-28:13:45:28,348 INFO     [task.py:355] Building contexts for task on rank 0...\n","2024-03-28:13:45:28,767 INFO     [task.py:355] Building contexts for task on rank 1...\n","2024-03-28:13:45:29,606 INFO     [evaluator.py:319] Running loglikelihood requests\n","2024-03-28:13:45:29,606 INFO     [evaluator.py:319] Running loglikelihood requests\n","  0% 0/532 [00:00<?, ?it/s][2024-03-28 13:45:29,838] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-03-28 13:45:29,855] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","100% 532/532 [00:22<00:00, 23.69it/s]\n","fatal: not a git repository (or any parent up to mount point /)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","hf (pretrained=/content/Mistral-8x7b-Medical-Finetune_QA_MCQ,load_in_4bit=True,dtype=bfloat16), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 32\n","|      Tasks       |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|------------------|-------|------|-----:|------|-----:|---|-----:|\n","|clinical_knowledge|Yaml   |none  |     0|acc   |0.7698|±  |0.0259|\n","\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"JgexYKatYW4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download('results_mmlu_clinical_knowledge.jsonl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"r6MHbZQoZk7S","executionInfo":{"status":"ok","timestamp":1711635244824,"user_tz":-120,"elapsed":13,"user":{"displayName":"","userId":""}},"outputId":"84a68eef-2cff-4757-c5ac-60f3c86d79a9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_bbc91356-bff8-4d06-a381-a7b224a44b7b\", \"results_mmlu_professional_medicine.jsonl\", 1806)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"-WgZhRonZyPH"},"execution_count":null,"outputs":[]}]}